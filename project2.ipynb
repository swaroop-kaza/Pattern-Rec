{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import tarfile\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "data = pd.read_csv(\"spam.csv\",encoding='latin-1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   v1                                                 v2\n",
       "0   0  Go until jurong point, crazy.. Available only ...\n",
       "1   0                      Ok lar... Joking wif u oni...\n",
       "2   1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   0  U dun say so early hor... U c already then say...\n",
       "4   0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del data['Unnamed: 2']\n",
    "del data['Unnamed: 3']\n",
    "del data['Unnamed: 4']\n",
    "\n",
    "data['v1'] = data['v1'].replace(['ham','spam'],[0,1])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572,)\n",
      "(5572,)\n"
     ]
    }
   ],
   "source": [
    "y = data['v1'].as_matrix()\n",
    "X_text = data['v2'].as_matrix() \n",
    "print(X_text.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 8536)\n",
      "(5572,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "sw = stopwords.words(\"english\")\n",
    "cv = CountVectorizer(stop_words =sw)\n",
    "tcv = cv.fit_transform(X_text).toarray()\n",
    "#print(cv.vocabulary_)\n",
    "print(tcv.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 8536)\n",
      "(5572,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words=sw,lowercase=True)\n",
    "X = vectorizer.fit_transform(X_text).toarray()\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4457, 8536)\n",
      "(4457,)\n",
      "(1115, 8536)\n",
      "(1115,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9443946188340807"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train,y_train)\n",
    "pred = clf.predict(X_test)\n",
    "accuracy_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.885201793721973"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train,y_train)\n",
    "pred = clf.predict(X_test)\n",
    "accuracy_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(hidden_layer_sizes=(500,500))\n",
    "clf.fit(X_train,y_train)\n",
    "pred = clf.predict(X_test)\n",
    "accuracy_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(gamma=0.1,C=1,kernel='rbf')\n",
    "clf.fit(X_train,y_train)\n",
    "pred = clf.predict(X_test)\n",
    "accuracy_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "y_train_oh=tf.one_hot(tf.cast(y_train,tf.int32),2)\n",
    "y_tr=sess.run(y_train_oh)\n",
    "y_test_oh=tf.one_hot(tf.cast(y_test,tf.int32),2)\n",
    "y_te=sess.run(y_test_oh)\n",
    "#print(y_tr.shape)\n",
    "#print(y_train,y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden_nodes1 = 2000\n",
    "num_hidden_nodes2 = 1000\n",
    "num_hidden_nodes3 = 256\n",
    "keep_prob = 0.5\n",
    "# numFeatures = the number of words extracted from each email\n",
    "numFeatures = X_train.shape[1]\n",
    "# numLabels = number of classes we are predicting (here just 2: Spam or Ham)\n",
    "numLabels = y_tr.shape[1]\n",
    "\n",
    "# Input data.\n",
    "  \n",
    "tf_train_dataset = tf.cast(tf.constant(X_train),tf.float32)\n",
    "tf_train_labels = tf.constant(y_tr)\n",
    "tf_test_dataset = tf.cast(tf.constant(X_test),tf.float32)\n",
    "    \n",
    "# Single mail input. \n",
    "tf_mail = tf.placeholder(tf.float32, shape=(1, numFeatures))\n",
    "  \n",
    "\n",
    "# Variables.\n",
    "weights1 = tf.Variable(tf.truncated_normal([numFeatures, num_hidden_nodes1],stddev=np.sqrt(2.0 / (numFeatures))),name=\"v1\")\n",
    "biases1 = tf.Variable(tf.zeros([num_hidden_nodes1]),name=\"v2\")\n",
    "\n",
    "weights2 = tf.Variable(tf.truncated_normal([num_hidden_nodes1, num_hidden_nodes2], stddev=np.sqrt(2.0 / num_hidden_nodes1)),name=\"v3\")\n",
    "biases2 = tf.Variable(tf.zeros([num_hidden_nodes2]),name=\"v4\")\n",
    "\n",
    "weights3 = tf.Variable(tf.truncated_normal([num_hidden_nodes2, num_hidden_nodes3], stddev=np.sqrt(2.0 / num_hidden_nodes2)),name=\"v5\")\n",
    "biases3 = tf.Variable(tf.zeros([num_hidden_nodes3]),name=\"v6\")\n",
    "\n",
    "weights4 = tf.Variable(tf.truncated_normal([num_hidden_nodes3, numLabels], stddev=np.sqrt(2.0 / num_hidden_nodes3)),name=\"v7\")\n",
    "biases4 = tf.Variable(tf.zeros([numLabels]),name=\"v8\")\n",
    "  \n",
    "    \n",
    "# Training computation.\n",
    "layer1_train = tf.nn.relu(tf.matmul(tf_train_dataset, weights1) + biases1)\n",
    "drop1 = tf.nn.dropout(layer1_train, keep_prob)\n",
    "layer2_train = tf.nn.relu(tf.matmul(drop1, weights2) + biases2)\n",
    "drop2 = tf.nn.dropout(layer2_train, keep_prob)\n",
    "layer3_train = tf.nn.relu(tf.matmul(drop2, weights3) + biases3)\n",
    "drop3 = tf.nn.dropout(layer3_train, keep_prob)\n",
    "logits = tf.matmul(drop3, weights4) + biases4\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=tf_train_labels))\n",
    "  \n",
    "# Optimizer.\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.1, beta1=0.9, beta2=0.999, epsilon=1e-08).minimize(loss)\n",
    "  \n",
    "# Predictions for the training, test data, and single mail.\n",
    "    \n",
    "train_prediction = tf.nn.softmax(logits)\n",
    "  \n",
    "layer1_test = tf.nn.relu(tf.matmul(tf_test_dataset, weights1) + biases1)\n",
    "layer2_test = tf.nn.relu(tf.matmul(layer1_test, weights2) + biases2)\n",
    "layer3_test = tf.nn.relu(tf.matmul(layer2_test, weights3) + biases3)\n",
    "test_prediction = tf.nn.softmax(tf.matmul(layer3_test, weights4) + biases4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 0: 0.702514\n",
      "Accuracy: 29.5%\n",
      "Loss at step 10: 0.434981\n",
      "Accuracy: 87.3%\n",
      "Loss at step 20: 0.386992\n",
      "Accuracy: 88.3%\n",
      "Loss at step 30: 0.390740\n",
      "Accuracy: 88.6%\n",
      "Loss at step 40: 0.368961\n",
      "Accuracy: 88.7%\n",
      "Loss at step 50: 0.380831\n",
      "Accuracy: 88.6%\n",
      "Loss at step 60: 0.377042\n",
      "Accuracy: 88.9%\n",
      "Loss at step 70: 0.358608\n",
      "Accuracy: 88.7%\n",
      "Loss at step 80: 0.346454\n",
      "Accuracy: 88.9%\n",
      "Loss at step 90: 0.356694\n",
      "Accuracy: 88.7%\n",
      "Loss at step 100: 0.342861\n",
      "Accuracy: 89.0%\n",
      "Loss at step 110: 0.349098\n",
      "Accuracy: 89.0%\n",
      "Loss at step 120: 0.365162\n",
      "Accuracy: 88.8%\n",
      "Loss at step 130: 0.350612\n",
      "Accuracy: 88.8%\n",
      "Loss at step 140: 0.342831\n",
      "Accuracy: 89.2%\n",
      "Loss at step 150: 0.345973\n",
      "Accuracy: 89.1%\n"
     ]
    }
   ],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))/ predictions.shape[0])\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "sess=tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "\n",
    "num_steps = 151\n",
    "for step in range(num_steps):\n",
    "    #feed={X:trainX,Y_:trainY,dropout_keep_prob:drop_train_keep}\n",
    "    _, l, predictions = sess.run([optimizer, loss, train_prediction])\n",
    "    acc = accuracy(predictions,y_tr)\n",
    "    if (step % 10 == 0):\n",
    "        print(\"Loss at step %d: %f\" % (step, l))\n",
    "        print(\"Accuracy: %.1f%%\" % acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 88.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"Test accuracy: %.1f%%\" % accuracy(sess.run(test_prediction), y_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_mat = np.cov(X_train.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_svd = tf.svd(cov_mat, full_matrices=False, compute_uv=True)\n",
    "s_tf, u_tf, v_tf = sess.run(tf_svd)\n",
    "#matrix_w=u_tf[:,0:PC_LIMIT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_eig = tf.self_adjoint_eig(cov_mat)\n",
    "eig_vals_tf, eig_vecs_tf = sess.run(tf_eig)\n",
    "print(eig_vals_tf.shape,eig_vecs_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8536, 8536)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.savetxt(\"eigenvalues.csv\",np.flip(np.sort(eig_vals_tf),axis=0), delimiter=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
